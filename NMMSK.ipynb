{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load data\ndata = pd.read_csv(\"CVD_cleaned.csv\")\n\n# Data Cleaning and Preprocessing\ndata = data.drop([\"Checkup\", \"Age_Category\"], axis=1)\n\n# Label Encoding\ncategorical_cols = [\"General_Health\", \"Exercise\", \"Heart_Disease\", \"Skin_Cancer\", \"Other_Cancer\", \"Depression\", \"Diabetes\", \"Arthritis\", \"Sex\", \"Smoking_History\"]\nle = LabelEncoder()\nfor col in categorical_cols:\n    data[col] = le.fit_transform(data[col])\n\n# Feature Importance\nX = data.drop(\"General_Health\", axis=1)\ny = data[\"General_Health\"]\nmodel = ExtraTreesClassifier()\nmodel.fit(X, y)\nfeature_importances = pd.Series(model.feature_importances_, index=X.columns)\nprint(\"Feature Importances:\")\nprint(feature_importances)\n\n# Split data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Dictionary of classification models\nmodels = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"Random Forest\": RandomForestClassifier(),\n    \"K-Nearest Neighbors (KNN)\": KNeighborsClassifier(),\n}\n\n# Train and evaluate each model\nresults = {}\nfor model_name, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    accuracy = accuracy_score(y_test, y_pred)\n    results[model_name] = accuracy\n    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n\n# Compare model performance\nplt.figure(figsize=(10, 6))\nplt.bar(results.keys(), results.values())\nplt.xlabel(\"Model\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Model Accuracy Comparison\")\nplt.show()\n\n# Choose the best model (example: Random Forest)\nbest_model = RandomForestClassifier()\nbest_model.fit(X_train, y_train)\ny_pred = best_model.predict(X_test)\n\n# Evaluation metrics for the best model\nprint(\"Best Model Classification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Confusion matrix for the best model\ncm = confusion_matrix(y_test, y_pred)\nsns.heatmap(cm, annot=True, fmt=\"d\")\nplt.title(\"Confusion Matrix (Best Model)\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()\n\n# Feature importance for the best model\nimportances = pd.Series(best_model.feature_importances_, index=X.columns)\nimportances.sort_values(ascending=True).plot(kind=\"barh\")\nplt.title(\"Feature Importance (Best Model)\")\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}